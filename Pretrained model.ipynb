{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K\n",
    "img_dim_ordering = 'tf'\n",
    "K.set_image_dim_ordering(img_dim_ordering)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_imgs_filename = '%s/X_train_imgs.csv' % data_dir\n",
    "X_val_imgs_filename = '%s/X_val_imgs.csv' % data_dir\n",
    "X_test_imgs_filename = '%s/X_test_imgs.csv' % data_dir\n",
    "y_train_filename = '%s/y_train.csv' % data_dir\n",
    "y_val_filename = '%s/y_val.csv' % data_dir\n",
    "y_test_filename = '%s/y_test.csv' % data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_img_files = read_img_file_csv(X_train_imgs_filename)\n",
    "X_val_img_files = read_img_file_csv(X_val_imgs_filename)\n",
    "X_test_img_files = read_img_file_csv(X_test_imgs_filename)\n",
    "y_train = read_label_file_csv(y_train_filename)\n",
    "y_val = read_label_file_csv(y_val_filename)\n",
    "y_test = read_label_file_csv(y_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_model(img_shape, num_classes, activation='relu', n=4096, lr=0.001):\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #model_vgg16_conv.summary()\n",
    "    \n",
    "    #Create your own input format\n",
    "    keras_input = Input(shape=img_shape, name = 'image_input')\n",
    "    \n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = model_vgg16_conv(keras_input)\n",
    "    \n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(n, activation=activation, name='fc1')(x)\n",
    "    x = Dense(n, activation=activation, name='fc2')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #Create your own model \n",
    "    pretrained_model = Model(inputs=keras_input, outputs=x)\n",
    "    optimizer = Adam(lr=lr)\n",
    "    pretrained_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imgs = read_imgs(X_train_img_files, scale_to_255=True)\n",
    "X_train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_load_imgs(X_img_files):\n",
    "    X_img_arr = []\n",
    "    for img_path in tqdm(X_img_files):\n",
    "        #print(img_path)\n",
    "        curr_img = image.load_img(img_path, target_size=(64, 64))\n",
    "        X_img_arr.append(curr_img.copy())\n",
    "        curr_img.close()\n",
    "\n",
    "    X_imgs = np.stack(X_img_arr)    \n",
    "    \n",
    "    return X_imgs.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_img_files, y_train = shuffle_train_data(X_train_img_files, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cutoff = int(0.1*len(y_train))\n",
    "_X_train_img_files = X_train_img_files[:cutoff]\n",
    "_y_train = y_train[:cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_X_train = vgg_load_imgs(_X_train_img_files)\n",
    "_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vgg_load_imgs(X_train_img_files)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].min(), X_train[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(X_train, start_idx=0, end_idx=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = vgg_load_imgs(X_val_img_files)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vgg_load_imgs(X_test_img_files)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pretrained_model((64, 64, 3), 2, n=512, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train, y=np.array(y_train), batch_size=32, epochs=10, verbose=2, callbacks=None, \n",
    "          validation_data=(X_val, np.array(y_val)), shuffle=True, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('%s/model.h5' % data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "        \n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    \n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    \n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            print(\"### ys:\", ys)\n",
    "            print(\"### xs:\", xs)\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            print(\"((%d, %d), (%d, %d))\" % startx, endx)\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "            \n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    \n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "        \n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_img_features(img):\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, model):    \n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img)\n",
    "        \n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = np.array(features).reshape(1, -1)\n",
    "        \n",
    "        #6) Predict using your classifier\n",
    "        prediction = model.predict(test_features)\n",
    "        \n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "            \n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = read_img('test_images/test1.jpg', scale_to_255=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_image = np.copy(image)\n",
    "\n",
    "# Uncomment the following line if you extracted training\n",
    "# data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# image you are searching is a .jpg (scaled 0 to 255)\n",
    "#image = image.astype(np.float32)/255\n",
    "\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "hot_windows = search_windows(image, windows, best_clf, \n",
    "                             spatial_feature_scaler, hist_feature_scaler, hog_feature_scalers,\n",
    "                             color_space=color_space, spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                             hist_range=hist_range, orient=hog_orient, \n",
    "                             pix_per_cell=hog_pix_per_cell, cell_per_block=hog_cell_per_block)\n",
    "\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "plt.imshow(window_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
